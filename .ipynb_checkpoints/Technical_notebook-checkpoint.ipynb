{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TECHNICAL NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Machine Learning and Natural Language Processing to predict stock price movements from article headlines\n",
    "\n",
    "## Research question\n",
    "\n",
    "Can we predict the <b>companies performance on the stockmarket based on the headlines</b> of the news articles?\n",
    "\n",
    "## Dataset\n",
    "\n",
    "For this project I retrieved headlines from WSJ online of 6 companies <b>between 2010/01/01 and 2019/11/22</b>, after preprocessing I got <b>6202 observations</b>.\n",
    "\n",
    "For labeling the dataset I used daily stockprices which are available on Yahoo Finance.\n",
    "\n",
    "The performance was <b>good</b>, if the closed stock price compared to the previous day was 0.5 %point better the S&P500 average. \n",
    "\n",
    "The performance was <b>bad</b>, if that stock performance was 0.5 %point worse than the S&P500 average.\n",
    "\n",
    "## Modeling\n",
    "\n",
    "The following Machine Learning algorithms was used to make predictions:\n",
    "\n",
    "- Logistic Regression\n",
    "- K-Nearest Neighbors\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- AdaBoost Classifier\n",
    "- XG Boosting\n",
    "- Support Vector Machine\n",
    "\n",
    "\n",
    "## Findings\n",
    "\n",
    "*\n",
    "*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T02:18:10.314793Z",
     "start_time": "2019-11-27T02:18:09.600383Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T02:18:13.358135Z",
     "start_time": "2019-11-27T02:18:13.225985Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T02:18:17.031151Z",
     "start_time": "2019-11-27T02:18:17.026507Z"
    }
   },
   "outputs": [],
   "source": [
    "# create our training data list - this is a list of text of headlines/summaries\n",
    "train_data = train['tokens'].to_list()\n",
    "test_data = test['tokens'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T02:18:24.720365Z",
     "start_time": "2019-11-27T02:18:24.712119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data:  4961\n",
      "Number of test data:   1241\n"
     ]
    }
   ],
   "source": [
    "print('Number of train data: ',len(train_data))\n",
    "print('Number of test data:  ',len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countvectorizer\n",
    "\n",
    "Here I instantiate a CountVectorizer. This counts the number of appearances of all the words in our training data. During the preprocessing stopword were removed and text was tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T02:18:49.364914Z",
     "start_time": "2019-11-27T02:18:46.385076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_data:  (4961, 5000) \n",
      "Shape of test_data:   (1241, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer=\"word\",\n",
    "                             tokenizer=None,\n",
    "                             preprocessor=None,\n",
    "                             max_features=5000,\n",
    "                             ngram_range=(1, 3))\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(train_data).toarray()\n",
    "test_data_features = vectorizer.transform(test_data).toarray()\n",
    "\n",
    "# check shapes\n",
    "print('Shape of train_data: ', train_data_features.shape,\n",
    "      '\\nShape of test_data:  ', test_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T02:18:51.753237Z",
     "start_time": "2019-11-27T02:18:51.741881Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T02:18:54.823240Z",
     "start_time": "2019-11-27T02:18:54.816011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train target:  (4961,) \n",
      "Shape of test target:   (1241,)\n"
     ]
    }
   ],
   "source": [
    "#restructure the target variable\n",
    "y_train = train.label\n",
    "y_test = test.label\n",
    "\n",
    "#check the shapes of target variable\n",
    "print('Shape of train target: ', y_train.shape,\n",
    "      '\\nShape of test target:  ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T02:18:56.894323Z",
     "start_time": "2019-11-27T02:18:56.851641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral    0.352550\n",
       "bad        0.331385\n",
       "good       0.316065\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T02:18:58.811540Z",
     "start_time": "2019-11-27T02:18:58.799299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral    0.352941\n",
       "bad        0.331185\n",
       "good       0.315874\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T02:20:03.948534Z",
     "start_time": "2019-11-27T02:19:06.836490Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score: 0.992\n",
      "Test accuracy score: 0.370\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Perform baseline logistic regression\n",
    "logreg_base = LogisticRegression(C = 1e9, \n",
    "                                 solver='lbfgs', \n",
    "                                 max_iter=1000, \n",
    "                                 penalty='l2',\n",
    "                                 multi_class = 'multinomial',\n",
    "                                 random_state=110)\n",
    "\n",
    "logreg_base.fit(train_data_features, y_train)\n",
    "\n",
    "print('Train accuracy score:',f'{logreg_base.score(train_data_features, y_train):.3f}')\n",
    "print('Test accuracy score:',f'{logreg_base.score(test_data_features, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression \n",
    "### Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed: 33.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'saga'}\n",
      "Best score: 0.414\n",
      "Test score: 0.430\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# gridsearch original parameters:\n",
    "params = [\n",
    "          {'C': np.logspace(-2, 4, 7),\n",
    "           'penalty': ['l1', 'l2'],\n",
    "           'solver': ['liblinear'],\n",
    "           'multi_class': ['ovr']\n",
    "           },\n",
    "          {'C': np.logspace(-2, 4, 7),\n",
    "           'penalty': ['l1', 'l2'],\n",
    "           'solver': ['saga'],\n",
    "           'multi_class': ['multinomial']\n",
    "           }]\n",
    "\n",
    "# gridsearch best parameters:\n",
    "# params = {'C': [0.01],\n",
    "#           'penalty': ['l2'],\n",
    "#           }\n",
    "\n",
    "logreg_grid = GridSearchCV(estimator=LogisticRegression(random_state=111),\n",
    "                           param_grid=params,\n",
    "                           scoring='accuracy',\n",
    "                           refit='accuracy',\n",
    "                           return_train_score = True,\n",
    "                           cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "#fit the model\n",
    "logreg_grid.fit(train_data_features, y_train)\n",
    "\n",
    "#priting out the result\n",
    "print(f'Best parameters: {logreg_grid.best_params_}')\n",
    "print(f'''Train accuracy score: \n",
    "          {logreg_grid.best_estimator_.score(train_data_features, y_train):.3f}''')\n",
    "print(f'''Test accuracy score: \n",
    "          {logreg_grid.best_estimator_.score(test_data_features, y_test):.3f}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T02:23:32.862218Z",
     "start_time": "2019-11-27T02:23:21.166901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-68c94ba77368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                            cv=5, verbose=2, n_jobs=5)\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mforest_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#priting out the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# params = {'n_estimators': [10, 100, 200, 500],\n",
    "#           'criterion': ['gini', 'entropy'],\n",
    "#           'max_depth': [2, 4, 6, 8, 10],\n",
    "#           'max_features': [5, 10, 20, 50]}\n",
    "\n",
    "params = {'n_estimators': [150, 200, 300, 400],\n",
    "          'criterion': ['gini'],\n",
    "          'max_depth': [9, 10, 11, 12],\n",
    "          'max_features': [50, 100, 500]}\n",
    "\n",
    "forest_grid = GridSearchCV(estimator=RandomForestClassifier(random_state=110),\n",
    "                           param_grid=params,\n",
    "                           scoring='accuracy',\n",
    "                           refit='accuracy',\n",
    "                           return_train_score=True,\n",
    "                           cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "forest_grid.fit(train_data_features, y_train)\n",
    "\n",
    "#priting out the result\n",
    "print(f'Best parameters: {forest_grid.best_params_}')\n",
    "print(f'''Train accuracy score: \n",
    "         {forest_grid.best_estimator_.score(train_data_features, y_train):.3f}''')\n",
    "print(f'''Test accuracy score: \n",
    "         {forest_grid.best_estimator_.score(test_data_features, y_test):.3f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_imp_forest = pd.DataFrame(zip(vocab, forest_grid.best_estimator_.feature_importances_), \n",
    "#                         columns=['Feature', 'Importance'])\n",
    "# feat_imp_forest.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "# feat_imp_forest.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "params = {'n_neighbors': range(1, 30, 2)}\n",
    "\n",
    "knn_grid = GridSearchCV(estimator=KNeighborsClassifier(random_state=110),\n",
    "                           param_grid=params,\n",
    "                           scoring='accuracy',\n",
    "                           refit='accuracy',\n",
    "                           return_train_score=True,\n",
    "                           cv=5, verbose=2, n_jobs=5)\n",
    "\n",
    "knn_grid.fit(train_data_features, y_train)\n",
    "\n",
    "print(f'Best parameters: {forest_grid.best_params_}')\n",
    "print(f'''Train accuracy score: \n",
    "          {forest_grid.best_estimator_.score(train_data_features, y_train):.3f}''')\n",
    "print(f'''Test accuracy score: \n",
    "          {forest_grid.best_estimator_.score(test_data_features, y_test):.3f}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "params = {\"learning_rate\": [0.1, 0.2, 0.4],\n",
    "          'max_depth': [2, 3, 4, 5, 8, 10],\n",
    "          'max_features': [5, 10, 50, 100, 200],\n",
    "          'n_estimators': [10, 50, 100, 200],\n",
    "          }\n",
    "\n",
    "gboost_grid = GridSearchCV(estimator=GradientBoostingClassifier(random_state=111),\n",
    "                       param_grid=param_grid_gboost,\n",
    "                       scoring='accuracy',\n",
    "                       refit='accuracy',\n",
    "                       return_train_score=True,\n",
    "                       cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gboost_grid.fit(train_data_features, y_train)\n",
    "\n",
    "#priting out the result\n",
    "print(f'Best parameters: {gboost_grid.best_params_}')\n",
    "print(f'''Train accuracy score: \n",
    "          {gboost_grid.best_estimator_.score(train_data_features, y_train):.3f}''')\n",
    "print(f'''Test accuracy score: \n",
    "          {gboost_grid.best_estimator_.score(test_data_features, y_test):.3f}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "params = {\"learning_rate\": [0.1, 0.2, 0.4],\n",
    "          'max_depth': [2, 3, 4, 5, 8, 10],\n",
    "          'max_features': [5, 10, 50, 100, 200],\n",
    "          'n_estimators': [10, 50, 100, 200],\n",
    "          }\n",
    "\n",
    "adaboost_grid = GridSearchCV(estimator=AdaBoostClassifier(algorithm='SAMME.R', \n",
    "                                                          random_state=111),\n",
    "                            param_grid=param_grid_gboost,\n",
    "                            scoring='accuracy',\n",
    "                            refit='accuracy',\n",
    "                            return_train_score=True,\n",
    "                            cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "adaboost_grid.fit(train_data_features, y_train)\n",
    "\n",
    "#priting out the result\n",
    "print(f'Best parameters: {gboost_grid.best_params_}')\n",
    "print(f'''Train accuracy score: \n",
    "          {gboost_grid.best_estimator_.score(train_data_features, y_test):.3f}''')\n",
    "print(f'''Test accuracy score: \n",
    "          {gboost_grid.best_estimator_.score(test_data_features, y_test):.3f}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "params = {\"learning_rate\": [0.1, 0.2, 0.4],\n",
    "          'max_depth': [2, 3, 4, 5, 8, 10],\n",
    "          'max_features': [5, 10, 50, 100, 200],\n",
    "          'n_estimators': [10, 50, 100, 200],\n",
    "          }\n",
    "\n",
    "adaboost_grid = GridSearchCV(estimator=AdaBoostClassifier(algorithm='SAMME.R', random_state=111),\n",
    "                       param_grid=param_grid_gboost,\n",
    "                       scoring='accuracy',\n",
    "                       refit='accuracy',\n",
    "                       return_train_score=True,\n",
    "                       cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "adaboost_grid.fit(train_data_features, y_train)\n",
    "\n",
    "#priting out the result\n",
    "print(f'Best parameters: {gboost_grid.best_params_}')\n",
    "print(f'Train accuracy score: {gboost_grid.best_estimator_.score(train_data_features, y_test):.3f}')\n",
    "print(f'Test accuracy score: {gboost_grid.best_estimator_.score(test_data_features, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "params = {'kernel': ['linear', 'poly', 'rbf'],\n",
    "          'C': [0.1, 1, 10, 1000], #high C allows narrow mistakes\n",
    "          'degree': [2, 3]}\n",
    "\n",
    "svm_grid = GridSearchCV(estimator=svm_clf,\n",
    "                       param_grid=param_grid_svm,\n",
    "                       scoring='accuracy',\n",
    "                       return_train_score=True,\n",
    "                       cv=3, verbose=2,        n_jobs=5)\n",
    "\n",
    "\n",
    "svm_grid.fit(train_data_features, y_train)\n",
    "\n",
    "#priting out the result\n",
    "print(f'Best parameters: {svm_grid.best_params_}')\n",
    "print(f'Train accuracy score: {svm_grid.best_estimator_.score(train_data_features, y_test):.3f}')\n",
    "print(f'Test accuracy score: {svm_grid.best_estimator_.score(test_data_features, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
