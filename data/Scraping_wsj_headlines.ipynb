{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping headlines - final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To collect headlines and short summaries I scraped <b>WSJ online</b>, where these information were availabele without subscription. This notebook contains all the necessary codes how to go trough the process.\n",
    "\n",
    "For scraping headlines I was using Selenium. For this purpose a chromedriver should be installed at the some folder. The scraped headlines were collected directly to a Mongodb document, which allowed us to collect these in real time. The biggest adventage if it was, that if a process ended with error (finally it didn't happen), the already scraped headlines wouldn't get lost. In Mongodb GUI it was possible to check realtime the collected documents.\n",
    "\n",
    "The collected headlines should go throug a cleaning process, because the majority of articles not really connected to the company.\n",
    "\n",
    "<b>The targeted companies:</b>\n",
    "\n",
    "* General Electric (GE)\n",
    "* Goldman Sachs\n",
    "* Ford Motor\n",
    "* Tesla\n",
    "* International Business Machines (IBM)\n",
    "* Boeing\n",
    "* Goldman Sachs\n",
    "* JPMorgan\n",
    "* Microsoft\n",
    "* General Motors\n",
    "* Chrysler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and create useful instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "import json\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated random sleeptimes\n",
    "sleep_time = np.random.normal(loc=15, scale=5, size=100).round(3) # the sleep time average is 15 seconds\n",
    "sleep_time = sleep_time[sleep_time > 5]  #the sleep time is not shorter than 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Mongodb document to store the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "# create a Mongodb document\n",
    "myclient = pymongo.MongoClient(\"mongodb://127.0.0.1:27017/\")\n",
    "news = myclient['news']\n",
    "\n",
    "# create collection if not exist - example:\n",
    "# news.create_collection('tesla_news')\n",
    "\n",
    "# my collections:\n",
    "tesla_news = news['tesla_news']\n",
    "ge_news = news['ge_news']\n",
    "ibm_news = news['ibm_news']\n",
    "goldman_news = news['goldman_news']\n",
    "ford_news = news['ford_news']\n",
    "boeing_news = news['boeing_news']\n",
    "microsoft_news = news['microsoft_news']\n",
    "jpmorgan_news = news['jpmorgan_news']\n",
    "gm_news = news['gm_news']\n",
    "chrysler_news = news['chrysler_news']\n",
    "test_news = news['test_news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['127.0.0.1:27017'], document_class=dict, tz_aware=False, connect=True), 'news'), 'test_news')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create collection if not exist - example:\n",
    "news.create_collection('test_news')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOP - Class and methods for retrieving headlines and summary texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebNavigator:\n",
    "    '''\n",
    "    This class initiates a chrome webdriver.\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.driver = webdriver.Chrome('/Users/flatironschool/chromedriver')\n",
    "        # if there is a modification, the version num helps to track it down\n",
    "        print('Version2')\n",
    "\n",
    "    def navigate(self, url):\n",
    "        self.driver.get(url)\n",
    "\n",
    "    def get_headlines(self, first_page, collection, num_of_pages=1):\n",
    "        '''\n",
    "        This method retrievs and saves the headlines and summeries to a MongoDB collection.\n",
    "        -------------------------------------------------------\n",
    "        Inputs:\n",
    "            first_page: url of the first page of the search result\n",
    "            num_of_pages: the number of pages of the search results\n",
    "            collection: name of the Mongodb collection where to save the scraped headlines\n",
    "        -------------------------------------------------------\n",
    "        Returns:\n",
    "            there is no return, everything is saved directly to Mongodb collection\n",
    "        '''\n",
    "\n",
    "        # create the search urls from the first urls page and the number of pages\n",
    "        if num_of_pages > 1:\n",
    "            search_urls = [first_page] + [first_page + f'&page={n}' \n",
    "                                          for n in range(2, num_of_pages+1)]\n",
    "        else:\n",
    "            search_urls = [first_page]\n",
    "\n",
    "        for url in search_urls:\n",
    "            self.url = url\n",
    "            self.driver.get(url)\n",
    "            # being polite avg 15 sec\n",
    "            time.sleep(np.random.choice(sleep_time, 1).item())\n",
    "            headline_containers = self.driver.find_elements_by_class_name(\n",
    "                'headline-container')\n",
    "\n",
    "            for hc in headline_containers:\n",
    "                # -------------topic---------------\n",
    "                try:\n",
    "                    topic = hc.find_element_by_class_name(\n",
    "                        'category').find_element_by_tag_name('a').text\n",
    "                except:\n",
    "                    topic = 'nan'\n",
    "                # ------------headline-------------\n",
    "                try:\n",
    "                    headline = hc.find_element_by_class_name(\n",
    "                        'headline').find_element_by_tag_name('a').text\n",
    "                except:\n",
    "                    continue\n",
    "                # --------------summary-------------\n",
    "                try:\n",
    "                    summary = hc.find_element_by_class_name(\n",
    "                        'summary-container').find_element_by_tag_name('p').text\n",
    "                except:\n",
    "                    summary = 'nan'\n",
    "                # ---------------date---------------\n",
    "                try:\n",
    "                    date = hc.find_element_by_tag_name('time').text\n",
    "                except:\n",
    "                    continue\n",
    "                # ---------------url-----------------\n",
    "                try:\n",
    "                    url = hc.find_element_by_class_name(\n",
    "                        'headline').find_element_by_tag_name('a').get_attribute('href')\n",
    "                except:\n",
    "                    url = 'nan'\n",
    "\n",
    "                # ---------insert document into collection-------\n",
    "                document = {'headline': headline,\n",
    "                            'summary': summary,\n",
    "                            'topic': topic,\n",
    "                            'date': date,\n",
    "                            'url': url}\n",
    "                collection.insert_one(document)\n",
    "\n",
    "    def close(self):\n",
    "        '''This method closes the window.'''\n",
    "        self.driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_search(company, num_of_pages, collection):\n",
    "    '''\n",
    "    This function runs the search on the page.\n",
    "    Input:\n",
    "        company: the name we want to run the search on\n",
    "        num_of_pages: the resulted number of pages\n",
    "        collection: which collection to save in\n",
    "    Returns:\n",
    "        the collected documents are saved in the given collection\n",
    "    '''\n",
    "    search_url=f'https://www.wsj.com/search/term.html?KEYWORDS={company}&min-date=2010/01/01&max-date=2019/11/22&isAdvanced=true&daysback=90d&andor=AND&sort=date-desc&source=wsjarticle'\n",
    "    \n",
    "    webpage = WebNavigator()\n",
    "    try:\n",
    "        webpage.get_headlines(search_url, collection, num_of_pages=num_of_pages)\n",
    "    except:\n",
    "        print('error: ', webpage.url)\n",
    "    webpage.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting the headline/summary text from the search results\n",
    "\n",
    "\n",
    "\n",
    "The advanced search was generated manually on the website, where there was possible to identify the first result page and the number of result pages altogether. Each search result page contains 20 headlines, its topic category, date, short summary and url.\n",
    "\n",
    "The \"search_result\" variable contains the first page of the search result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tesla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version2\n"
     ]
    }
   ],
   "source": [
    "pages = 144\n",
    "collection = tesla_news\n",
    "run_search('Tesla', pages, collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version2\n"
     ]
    }
   ],
   "source": [
    "pages = 146\n",
    "collection = ge_news\n",
    "run_search('GE', pages, collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version2\n"
     ]
    }
   ],
   "source": [
    "pages = 101\n",
    "collection = ibm_news\n",
    "run_search('IBM', pages, collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ford:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version2\n"
     ]
    }
   ],
   "source": [
    "pages = 515\n",
    "collection = ford_news\n",
    "run_search('Ford', pages, collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goldman Sachs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version2\n"
     ]
    }
   ],
   "source": [
    "pages = 702\n",
    "collection = goldman_news\n",
    "run_search('Goldman', pages, collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boeing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version2\n"
     ]
    }
   ],
   "source": [
    "pages = 348\n",
    "collection = boeing_news\n",
    "run_search('Boeing', pages, collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JPMorgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = 104\n",
    "collection = jpmorgan_news\n",
    "run_search('JPMorgan', pages, collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = 429\n",
    "collection = microsoft_news\n",
    "run_search('Microsoft', pages, collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version2\n"
     ]
    }
   ],
   "source": [
    "pages = 491\n",
    "collection = gm_news\n",
    "run_search('General%20Motors', pages, collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chrysler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version2\n"
     ]
    }
   ],
   "source": [
    "pages = 181\n",
    "collection = chrysler_news\n",
    "run_search('Chrysler', pages, collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version2\n"
     ]
    }
   ],
   "source": [
    "search_url = 'https://www.wsj.com/search/term.html?KEYWORDS=General%20Motors%20Tesla%20IBM%20Ford%20GE%20Boeing%20Chrysler%20Microsoft&min-date=2019/11/23&max-date=2019/12/04&isAdvanced=true&daysback=90d&andor=OR&sort=date-desc&source=wsjarticle'\n",
    "collection = test_news\n",
    "num_of_pages = 27\n",
    "webpage = WebNavigator()\n",
    "try:\n",
    "    webpage.get_headlines(search_url, collection, num_of_pages=num_of_pages)\n",
    "except:\n",
    "    print('error: ', webpage.url)\n",
    "webpage.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check the number of documents in Mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla 2735\n",
      "GE 2838\n",
      "IBM 1983\n",
      "Ford 10015\n",
      "Goldman 12927\n",
      "Boeing 6529\n",
      "JPMorgan 2071\n",
      "Microsoft 8514\n",
      "General Motors 9415\n",
      "Chrysler 3529\n"
     ]
    }
   ],
   "source": [
    "print('Tesla', tesla_news.estimated_document_count())\n",
    "print('GE', ge_news.estimated_document_count())\n",
    "print('IBM', ibm_news.estimated_document_count())\n",
    "print('Ford', ford_news.estimated_document_count())\n",
    "print('Goldman', goldman_news.estimated_document_count())\n",
    "print('Boeing', boeing_news.estimated_document_count())\n",
    "print('JPMorgan', jpmorgan_news.estimated_document_count())\n",
    "print('Microsoft', microsoft_news.estimated_document_count())\n",
    "print('General Motors', gm_news.estimated_document_count())\n",
    "print('Chrysler', chrysler_news.estimated_document_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
