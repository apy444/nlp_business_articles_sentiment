{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the process to compile datasets for modeling purpose.\n",
    "\n",
    "#### The main steps of the process:\n",
    "\n",
    "- Reading in stock price datasets, resturcturing and creating price based labels\n",
    "\n",
    "- Reading in article headlines, stemming and tokenizing the text\n",
    "\n",
    "- Merging and concatenate the article headlines and lables\n",
    "\n",
    "- Split into train and test dataset\n",
    "\n",
    "- Saving into a csv file\n",
    "\n",
    "\n",
    "In order to compare the company's performance I used <b>S&P500</b> index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:41:12.235850Z",
     "start_time": "2019-11-27T12:41:12.223457Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_row', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1. Preprocessing the stock price datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:16:41.403135Z",
     "start_time": "2019-11-28T02:16:41.398745Z"
    },
    "hidden": true
   },
   "source": [
    "### 1.1. Importing the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Source: https://finance.yahoo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "companies = ['tesla', 'ford', 'ibm', 'goldman', 'boeing', 'ge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:40:00.970908Z",
     "start_time": "2019-11-27T12:40:00.886298Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "sp500 = pd.read_csv('financial/SP500.csv')\n",
    "\n",
    "tesla_stock = pd.read_csv('financial/TSLA.csv')\n",
    "ford_stock = pd.read_csv('financial/F.csv')\n",
    "ibm_stock = pd.read_csv('financial/IBM.csv')\n",
    "goldman_stock = pd.read_csv('financial/GS.csv')\n",
    "boeing_stock = pd.read_csv('financial/BA.csv')\n",
    "ge_stock = pd.read_csv('financial/GE.csv')\n",
    "jpm_stock = pd.read_csv('financial/JPM.csv')\n",
    "microsoft_stock = pd.read_csv('financial/MSFT.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 1.2. Restructuring/labeling stock data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Labeling rule:\n",
    "* <b>good</b>: if the company share price performed better than the index\n",
    "* <b>bad</b>: if the company share price performed worse than the index\n",
    "\n",
    "Calculation:\n",
    "* For calculating changes in stock prices 'Close' prices are used\n",
    "* 'change': % change compared to the previous day\n",
    "* 'nextday': % change of the following day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:00:05.567684Z",
     "start_time": "2019-11-28T02:00:05.527885Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def price_ratios(stock_data, index_data):\n",
    "    '''\n",
    "    This function returns a restructured dataframe for labeling purpose.\n",
    "\n",
    "    The function requires specific structure of the data, which is based on the current \n",
    "    datascource (yahoo/finance).\n",
    "\n",
    "    -------------------------\n",
    "    Inputs:\n",
    "        stock_data: dataframe\n",
    "        index_data: dataframe\n",
    "\n",
    "    -------------------------\n",
    "    Returns: dataframe\n",
    "\n",
    "    '''\n",
    "    # merge dataframes\n",
    "    df = pd.merge(stock_data, index_data, how='inner',\n",
    "                  on='Date', suffixes=('', '_i'))\n",
    "    \n",
    "    df.columns = df.columns.str.lower()\n",
    "    df = df[['date','close', 'close_i', 'volume']]\n",
    "    \n",
    "    # shifting prices by one day ahead and merge\n",
    "    df = df.set_index('date')\n",
    "    shifted_next = df.shift(periods=-1)\n",
    "    df = pd.merge(df, shifted_next, on='date', suffixes=('', '_next')) #next day prices\n",
    "    df = df.reset_index()\n",
    "     \n",
    "    # shifting prices by one day back and merge\n",
    "    df = df.set_index('date')\n",
    "    shifted_prev = df.shift(periods=1)\n",
    "    df = pd.merge(df, shifted_prev, on='date', suffixes=('', '_prev')) #previous day prices\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # calculate rolling means for the volume\n",
    "    df['volume_avg'] = df.volume.rolling(window=14).mean().fillna(method='backfill')\n",
    "    df['volume_ratio'] = round(df.volume / df.volume_avg, 2)\n",
    "    \n",
    "    # creating ratios\n",
    "    df['change'] = round(df['close'] / df['close_prev'] * 100 - 100, 4)\n",
    "    df['nextday'] = round(df['close_next'] / df['close'] * 100 - 100, 4)\n",
    "    df['change_i'] = round(df['close_i'] / df['close_i_prev'] * 100 - 100, 4)\n",
    "    df['nextday_i'] = round(df['close_i_next'] / df['close_i'] * 100 - 100, 4)\n",
    "\n",
    "    # adding trading holidays to the dataframe and fill\n",
    "    dates = []\n",
    "    last_day = pd.to_datetime(stock_data.iloc[-1, 0], format='%Y-%m-%d')\n",
    "    for i in range(3615):\n",
    "        date = last_day - datetime.timedelta(days=i)\n",
    "        date = date.strftime('%Y-%m-%d')\n",
    "        dates.append(date)\n",
    "    date_df = pd.DataFrame(dates, columns=['date'])\n",
    "    date_df = date_df.sort_values(by='date')\n",
    "    df = pd.merge(date_df, df, on='date', how='left')\n",
    "\n",
    "    # fill in trading holidays with the next valid data\n",
    "    df = df.fillna(method='backfill')\n",
    "    \n",
    "    df = df[['date', \n",
    "             'change', 'nextday', 'change_i', 'nextday_i', \n",
    "             'volume_ratio']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T01:07:06.402454Z",
     "start_time": "2019-11-28T01:07:06.397671Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# microsoft_test = price_ratios(microsoft_stock, sp500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T01:07:29.430233Z",
     "start_time": "2019-11-28T01:07:29.417315Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# microsoft_test.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T03:56:05.654702Z",
     "start_time": "2019-11-27T03:56:05.648437Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def label(df):\n",
    "    df.loc[df['change'] > df['change_i'] + 0.5, 'label'] = 2\n",
    "\n",
    "    df.loc[df['change'] < df['change_i'] - 0.5, 'label'] = 3\n",
    "\n",
    "    df.loc[df.label.isna(), 'label'] = 1\n",
    "    \n",
    "    df = df[['date', 'label']]\n",
    "    \n",
    "#     df.date = pd.to_datetime(df.date)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T03:56:09.114111Z",
     "start_time": "2019-11-27T03:56:09.105960Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def label(df):\n",
    "    df.loc[(df['change'] > df['change_i'])&(df['nextday'] > df['nextday_i']), 'label'] = 1\n",
    "\n",
    "    df.loc[(df['change'] < df['change_i'])&(df['nextday'] < df['nextday_i']), 'label'] = 0\n",
    "\n",
    "    df.loc[df.label.isna(), 'label'] = 999\n",
    "    \n",
    "    df = df[['date', 'label']]\n",
    "    \n",
    "#     df.date = pd.to_datetime(df.date)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:00:28.519892Z",
     "start_time": "2019-11-28T02:00:28.511269Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# this labeling takes into consideration the volume and the relative change\n",
    "\n",
    "def label(df):\n",
    "    df.loc[(df['change'] > df['change_i'] + 0.5)&(df['volume_ratio'] > 1), 'label'] = 1\n",
    "\n",
    "    df.loc[(df['change'] < df['change_i'] - 0.5)&(df['volume_ratio'] > 1), 'label'] = 0\n",
    "\n",
    "    df.loc[df.label.isna(), 'label'] = 999\n",
    "    \n",
    "#     df = df[['date', 'label']]\n",
    "    \n",
    "#     df.date = pd.to_datetime(df.date)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:00:49.311736Z",
     "start_time": "2019-11-28T02:00:47.182055Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tesla_label = label(price_ratios(tesla_stock, sp500))\n",
    "ford_label = label(price_ratios(ford_stock, sp500))\n",
    "ibm_label = label(price_ratios(ibm_stock, sp500))\n",
    "goldman_label = label(price_ratios(goldman_stock, sp500))\n",
    "boeing_label = label(price_ratios(boeing_stock, sp500))\n",
    "ge_label = label(price_ratios(ge_stock, sp500))\n",
    "jpm_label = label(price_ratios(jpm_stock, sp500))\n",
    "microsoft_label = label(price_ratios(microsoft_stock, sp500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T01:18:01.087996Z",
     "start_time": "2019-11-28T01:18:01.075825Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999.0    2647\n",
       "0.0      493 \n",
       "1.0      475 \n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {1: 'good', 999: 'neutral', 0: 'bad'}\n",
    "boeing_label.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 2. Preprocessing the article information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.1. Import headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T19:14:09.608670Z",
     "start_time": "2019-11-27T19:14:09.569754Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "myclient = pymongo.MongoClient(\"mongodb://127.0.0.1:27017/\")\n",
    "news = myclient['news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:02:58.424178Z",
     "start_time": "2019-11-28T02:02:57.778830Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tesla_news = pd.DataFrame.from_records(news.tesla_news.find())\n",
    "ford_news = pd.DataFrame.from_records(news.ford_news.find())\n",
    "ibm_news = pd.DataFrame.from_records(news.ibm_news.find())\n",
    "goldman_news = pd.DataFrame.from_records(news.goldman_news.find())\n",
    "boeing_news = pd.DataFrame.from_records(news.boeing_news.find())\n",
    "ge_news = pd.DataFrame.from_records(news.ge_news.find())\n",
    "jpmorgan_news = pd.DataFrame.from_records(news.jpmorgan_news.find())\n",
    "microsoft_news = pd.DataFrame.from_records(news.microsoft_news.find())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:11:48.354634Z",
     "start_time": "2019-11-28T02:11:48.349561Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.2. Concatenate headline and summary into one text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:20:36.630979Z",
     "start_time": "2019-11-28T02:20:36.626710Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def concat_news(some_news):\n",
    "    some_news['text'] = some_news.headline +' '+ some_news.summary\n",
    "    some_news = some_news[['date', 'text', 'topic']]\n",
    "    return some_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:20:57.890684Z",
     "start_time": "2019-11-28T02:20:57.746507Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tesla_news = concat_news(tesla_news)\n",
    "ford_news = concat_news(ford_news)\n",
    "ibm_news = concat_news(ibm_news)\n",
    "goldman_news = concat_news(goldman_news)\n",
    "boeing_news = concat_news(boeing_news)\n",
    "ge_news = concat_news(ge_news)\n",
    "jpmorgan_news = concat_news(jpmorgan_news)\n",
    "microsoft_news = concat_news(microsoft_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.3. Keeping just the relevant articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Relevant a headline or the summary, if it contains the keywords (basically the company name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:21:54.189562Z",
     "start_time": "2019-11-28T02:21:54.180076Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def relevant(text, keywords):\n",
    "    '''\n",
    "    Inputs:\n",
    "        text: string\n",
    "        keywords: list of string objects\n",
    "    Returns:\n",
    "        boolean\n",
    "    '''\n",
    "    for keyword in keywords:\n",
    "        if keyword in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def relevant_rows(df, keywords):\n",
    "    '''\n",
    "    Returns the rows of the dataframe, where the text is relevant\n",
    "    Input:\n",
    "        df: dataframe\n",
    "        keywords: list of string objects\n",
    "    Returns:\n",
    "        dataframe with the relevant rows\n",
    "    '''\n",
    "    df = df.loc[df.text.apply(lambda x: relevant(x, keywords))]\n",
    "    \n",
    "    print('Number of rows: ',len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:22:12.080460Z",
     "start_time": "2019-11-28T02:22:12.071845Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  933\n"
     ]
    }
   ],
   "source": [
    "tesla_news = relevant_rows(tesla_news, ['Tesla'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:22:34.134421Z",
     "start_time": "2019-11-28T02:22:34.117382Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  1447\n"
     ]
    }
   ],
   "source": [
    "ford_news = relevant_rows(ford_news, ['Ford'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:33:45.674461Z",
     "start_time": "2019-11-28T02:33:45.663837Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  509\n"
     ]
    }
   ],
   "source": [
    "ibm_news = relevant_rows(ibm_news, ['IBM', 'International Business Machines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:34:02.664212Z",
     "start_time": "2019-11-28T02:34:02.643880Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  1667\n"
     ]
    }
   ],
   "source": [
    "goldman_news = relevant_rows(goldman_news, ['Goldman'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:34:21.370039Z",
     "start_time": "2019-11-28T02:34:21.349996Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  1629\n"
     ]
    }
   ],
   "source": [
    "boeing_news = relevant_rows(boeing_news, ['Boeing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:34:39.665973Z",
     "start_time": "2019-11-28T02:34:39.649839Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  1085\n"
     ]
    }
   ],
   "source": [
    "ge_news = relevant_rows(ge_news, ['GE', 'General Electric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:34:58.053249Z",
     "start_time": "2019-11-28T02:34:58.037435Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  223\n"
     ]
    }
   ],
   "source": [
    "jpmorgan_news = relevant_rows(jpmorgan_news, ['JPMorgan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:35:16.764957Z",
     "start_time": "2019-11-28T02:35:16.743723Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  1416\n"
     ]
    }
   ],
   "source": [
    "microsoft_news = relevant_rows(microsoft_news, ['Microsoft'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.4. Converting dates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T01:19:07.123298Z",
     "start_time": "2019-11-28T01:19:07.120834Z"
    },
    "hidden": true
   },
   "source": [
    "If the article is published after the closing time of the stock market, I convert its date into the next day, becaues this article can affect only the next day price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:40:54.817677Z",
     "start_time": "2019-11-28T02:40:54.808921Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def converting_date(some_date):\n",
    "    # compares the published time of the article with the closure of the stockmarket\n",
    "    # if the article is published after the closure, it's date changed to the next day\n",
    "    if pd.to_datetime(some_date).time() > datetime.time(16, 0):\n",
    "        day = pd.to_datetime(some_date).date() + datetime.timedelta(days=1)\n",
    "    else:\n",
    "        day = pd.to_datetime(some_date).date()\n",
    "    return day.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:47:58.853893Z",
     "start_time": "2019-11-28T02:47:51.694012Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tesla_news.date = tesla_news.date.apply(converting_date)\n",
    "ford_news.date = ford_news.date.apply(converting_date)\n",
    "ibm_news.date = ibm_news.date.apply(converting_date)\n",
    "microsoft_news.date = microsoft_news.date.apply(converting_date)\n",
    "goldman_news.date = goldman_news.date.apply(converting_date)\n",
    "jpmorgan_news.date = jpmorgan_news.date.apply(converting_date)\n",
    "boeing_news.date = boeing_news.date.apply(converting_date)\n",
    "ge_news.date = ge_news.date.apply(converting_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.5. Stemming/tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The 'stopwords' and 'negativewords' were originally based on the stopwords of nltk library. For this sentiment\n",
    "analysis I reviewed and modified the content of stopwords (removed keywords, added some not predicting words).\n",
    "Words that change completely the meaning of the following words (I call them like 'negative words') will be replaced simply with 'not'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:49:21.998517Z",
     "start_time": "2019-11-28T02:49:21.979378Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_stopwords = ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an',\n",
    "                'and', 'any', 'are', 'as', 'at', 'be', 'because', 'been', 'before', 'being',\n",
    "                'between', 'both', 'but', 'by', 'can', 'd', 'did', 'do', 'does', 'doing', \n",
    "                'during', 'each', 'few', 'for', 'from', 'further', 'had', 'has', 'have', \n",
    "                'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', \n",
    "                'how', 'i', 'if', 'in', 'into', 'is', 'it', \"it's\", 'its', 'itself', 'just', \n",
    "                'll', 'm', 'ma', 'me', 'might', 'more', 'most', 'my', 'myself', 'neeed', \n",
    "                'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', \n",
    "                'ourselves', 'out', 'over', 'own', 're', 's', 'u', 't', 'same', 'she', \n",
    "                \"she's\", 'should', \"should've\", 'so', 'some', 'such', 'than', 'that', \"that'll\",\n",
    "                'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', \n",
    "                'they', 'this', 'k', 'those', 'through', 'to', 'too', 'until', 've', 'very', \n",
    "                'was', 'we', 'were', 'what', 'when', 'where', 'which', 'while', 'who', 'whom', \n",
    "                'why', 'will', 'with', 'would', 'could', 'y', 'you', \"you'd\", \"you'll\", \n",
    "                \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves', 'mr', 'mrs', \n",
    "                'ms', 'nan', 'inc', 'co', 'com', 'wsj', 'monday', 'tuesday', 'wednesday', \n",
    "                'thursday', 'friday', 'saturday', 'sunday', 'either', 'shall', 'must', 'with', \n",
    "                'without', 'may']\n",
    "\n",
    "# my_negativewords = [\"aren't\", \"couldn't\", \"didn't\", \"doesn't\", \"don't\",\n",
    "#                     \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\",\n",
    "#                     'neither', 'nor', \"mustn't\", \"needn't\", 'no', \"shan't\",\n",
    "#                     \"shouldn't\", \"wasn't\", \"weren't\", \"won't\", \"wouldn't\"]\n",
    "\n",
    "\n",
    "my_negativewords = ['aren', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', \n",
    "                    'mightn', 'no', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', \n",
    "                    'won', 'wouldn', 'neither', 'nor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:49:41.359886Z",
     "start_time": "2019-11-28T02:49:41.347681Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def my_tokenizer(text):\n",
    "    # just keep the words (remove characters and numbers)\n",
    "    token_list = re.findall(r'([a-zA-Z-]+)', text)\n",
    "\n",
    "    # lowercase\n",
    "    token_list = [t.lower() for t in token_list]\n",
    "\n",
    "    # remove stopwords\n",
    "    token_list = [word for word in token_list if word not in my_stopwords]\n",
    "\n",
    "    # replace negative words to 'not'\n",
    "    for i, word in enumerate(token_list):\n",
    "        if word in my_negativewords:\n",
    "            token_list[i] = 'not'\n",
    "    \n",
    "    # lemmatize\n",
    "    token_list = [wnl.lemmatize(word) for word in token_list]\n",
    "    \n",
    "    # converting list into text\n",
    "    token_text = ' '.join(token_list)\n",
    "\n",
    "    return token_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:50:02.375622Z",
     "start_time": "2019-11-28T02:50:00.467027Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tesla_news['tokens'] = tesla_news.text.apply(my_tokenizer)\n",
    "ford_news['tokens'] = ford_news.text.apply(my_tokenizer)\n",
    "ibm_news['tokens'] = ibm_news.text.apply(my_tokenizer)\n",
    "goldman_news['tokens'] = goldman_news.text.apply(my_tokenizer)\n",
    "boeing_news['tokens'] = boeing_news.text.apply(my_tokenizer)\n",
    "ge_news['tokens'] = ge_news.text.apply(my_tokenizer)\n",
    "jpmorgan_news['tokens'] = jpmorgan_news.text.apply(my_tokenizer)\n",
    "microsoft_news['tokens'] = microsoft_news.text.apply(my_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Merging/concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T02:51:02.014672Z",
     "start_time": "2019-11-28T02:51:01.929934Z"
    }
   },
   "outputs": [],
   "source": [
    "tesla = pd.merge(tesla_news, tesla_label, how='left', on='date')\n",
    "ford = pd.merge(ford_news, ford_label, how='left', on='date')\n",
    "ibm = pd.merge(ibm_news, ibm_label, how='left', on='date')\n",
    "goldman = pd.merge(goldman_news, goldman_label, how='left', on='date')\n",
    "boeing = pd.merge(boeing_news, boeing_label, how='left', on='date')\n",
    "ge = pd.merge(ge_news, ge_label, how='left', on='date')\n",
    "jpm = pd.merge(jpmorgan_news, jpm_label, how='left', on='date')\n",
    "microsoft = pd.merge(microsoft_news, microsoft_label, how='left', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T03:38:36.689689Z",
     "start_time": "2019-11-28T03:38:36.661764Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.concat([tesla, ford, ibm, goldman, boeing, ge, jpm, microsoft])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T04:15:07.188948Z",
     "start_time": "2019-11-28T04:15:07.185235Z"
    }
   },
   "source": [
    "#### Exploration on topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T07:48:15.141620Z",
     "start_time": "2019-11-28T07:48:15.135349Z"
    }
   },
   "outputs": [],
   "source": [
    "# data.loc[data.label!=999].topic.value_counts().index.to_list()[:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T07:47:51.807279Z",
     "start_time": "2019-11-28T07:47:51.801520Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data.loc[data.topic=='REVIEW & OUTLOOK (U.S.)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T07:48:40.410223Z",
     "start_time": "2019-11-28T07:48:40.403422Z"
    }
   },
   "outputs": [],
   "source": [
    "# data.loc[data.date=='2011-01-07']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Removing not relevant topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T07:36:21.132411Z",
     "start_time": "2019-11-28T07:36:21.099915Z"
    }
   },
   "outputs": [],
   "source": [
    "# first I determine the relevant topics\n",
    "relevant_topics = data.loc[data.label!=999].topic.value_counts().index.to_list()[:26]\n",
    "for elem in ['PHOTOS', 'LETTERS', 'COMMENTARY', 'MANAGEMENT', 'POLITICS', 'BUSINESS WORLD',\n",
    "             'MULTIMEDIA', 'REVIEW & OUTLOOK (U.S.)']:\n",
    "    relevant_topics.remove(elem)\n",
    "    \n",
    "def relevant_topic(topic):\n",
    "    if topic in relevant_topics:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "data = data.loc[data.topic.apply(lambda x: relevant_topic(x))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Removing not polarizing articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T07:36:42.352436Z",
     "start_time": "2019-11-28T07:36:42.339191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999.0    4417\n",
       "0.0      1348\n",
       "1.0      1305\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T07:37:01.624483Z",
     "start_time": "2019-11-28T07:37:01.616684Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.loc[data.label != 999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T07:37:22.310699Z",
     "start_time": "2019-11-28T07:37:22.301005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2653, 10)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T07:39:14.126679Z",
     "start_time": "2019-11-28T07:39:14.118787Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T07:39:34.046264Z",
     "start_time": "2019-11-28T07:39:34.037790Z"
    }
   },
   "outputs": [],
   "source": [
    "data.drop(columns = 'index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T07:39:54.005361Z",
     "start_time": "2019-11-28T07:39:53.985354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>tokens</th>\n",
       "      <th>change</th>\n",
       "      <th>nextday</th>\n",
       "      <th>change_i</th>\n",
       "      <th>nextday_i</th>\n",
       "      <th>volume_ratio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>Microsoft, Abbott Laboratories: Money Flow Leaders (MSFT, ABT) Markets Data Center: Money Flow Leaders.</td>\n",
       "      <td>MARKETS</td>\n",
       "      <td>microsoft abbott laboratory money flow leader msft abt market data center money flow leader</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>0.7777</td>\n",
       "      <td>-1.0823</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>Intel, IBM Lift Dow; Baidu Hits New Peak Stocks rose as hopes for a strong earnings report from Intel boosted technology stocks including Microsoft and International Business Machines.</td>\n",
       "      <td>nan</td>\n",
       "      <td>intel ibm lift dow baidu hit new peak stock rose hope strong earnings report intel boosted technology stock including microsoft international business machine</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>0.7777</td>\n",
       "      <td>-1.0823</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  \\\n",
       "2651  2010-01-15   \n",
       "2652  2010-01-15   \n",
       "\n",
       "                                                                                                                                                                                          text  \\\n",
       "2651  Microsoft, Abbott Laboratories: Money Flow Leaders (MSFT, ABT) Markets Data Center: Money Flow Leaders.                                                                                    \n",
       "2652  Intel, IBM Lift Dow; Baidu Hits New Peak Stocks rose as hopes for a strong earnings report from Intel boosted technology stocks including Microsoft and International Business Machines.   \n",
       "\n",
       "        topic  \\\n",
       "2651  MARKETS   \n",
       "2652  nan       \n",
       "\n",
       "                                                                                                                                                              tokens  \\\n",
       "2651  microsoft abbott laboratory money flow leader msft abt market data center money flow leader                                                                      \n",
       "2652  intel ibm lift dow baidu hit new peak stock rose hope strong earnings report intel boosted technology stock including microsoft international business machine   \n",
       "\n",
       "      change  nextday  change_i  nextday_i  volume_ratio  label  \n",
       "2651 -0.323   0.7777  -1.0823    1.25       1.31          1.0    \n",
       "2652 -0.323   0.7777  -1.0823    1.25       1.31          1.0    "
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 4. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T07:42:30.385026Z",
     "start_time": "2019-11-28T07:42:30.371117Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = data.sort_values(by='date', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T07:46:21.230495Z",
     "start_time": "2019-11-28T07:46:21.225006Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_test = data[:350]\n",
    "data_train = data[350:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test = train_test_split(data,\n",
    "                                         test_size=.20,\n",
    "                                         random_state=10,\n",
    "                                         stratify=data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T07:46:48.159600Z",
     "start_time": "2019-11-28T07:46:48.147387Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1158\n",
       "1.0    1145\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T07:47:07.697173Z",
     "start_time": "2019-11-28T07:47:07.684632Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    190\n",
       "1.0    160\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 5. Save into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T07:47:28.235679Z",
     "start_time": "2019-11-28T07:47:28.139384Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_train.to_csv('train.csv')\n",
    "data_test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
