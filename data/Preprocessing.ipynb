{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the process to compile datasets for modeling purpose.\n",
    "\n",
    "#### The main steps of the process:\n",
    "\n",
    "- Reading in stock price datasets, resturcturing and creating price based labels\n",
    "\n",
    "- Reading in article headlines, stemming and tokenizing the text\n",
    "\n",
    "- Merging and concatenate the article headlines and lables\n",
    "\n",
    "- Split into train and test dataset\n",
    "\n",
    "- Saving into a csv file\n",
    "\n",
    "\n",
    "In order to compare the company's performance I used <b>S&P500</b> index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_row', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading in stock price datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source: https://finance.yahoo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = ['tesla', 'ford', 'ibm', 'goldman', 'boeing', 'ge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = pd.read_csv('financial/SP500.csv')\n",
    "\n",
    "tesla_stock = pd.read_csv('financial/TSLA.csv')\n",
    "ford_stock = pd.read_csv('financial/F.csv')\n",
    "ibm_stock = pd.read_csv('financial/IBM.csv')\n",
    "goldman_stock = pd.read_csv('financial/GS.csv')\n",
    "boeing_stock = pd.read_csv('financial/BA.csv')\n",
    "ge_stock = pd.read_csv('financial/GE.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>25.00</td>\n",
       "      <td>17.540001</td>\n",
       "      <td>23.889999</td>\n",
       "      <td>23.889999</td>\n",
       "      <td>18766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>25.790001</td>\n",
       "      <td>30.42</td>\n",
       "      <td>23.299999</td>\n",
       "      <td>23.830000</td>\n",
       "      <td>23.830000</td>\n",
       "      <td>17187100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open   High        Low      Close  Adj Close    Volume\n",
       "0  2010-06-29  19.000000  25.00  17.540001  23.889999  23.889999  18766300\n",
       "1  2010-06-30  25.790001  30.42  23.299999  23.830000  23.830000  17187100"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_stock.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Restructuring/labeling stock data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labeling rule:\n",
    "* <b>good</b>: if the company share price performed better than the index\n",
    "* <b>bad</b>: if the company share price performed worse than the index\n",
    "\n",
    "Calculation:\n",
    "* For calculating changes in stock prices 'Close' prices are used\n",
    "* 'change': % change compared to the previous day\n",
    "* 'nextday': % change of the following day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_ratios(stock_data, index_data):\n",
    "    '''\n",
    "    This function returns a restructured dataframe for labeling purpose.\n",
    "\n",
    "    The function requires specific structure of the data, which is based on the current \n",
    "    datascource (yahoo/finance).\n",
    "\n",
    "    -------------------------\n",
    "    Inputs:\n",
    "        stock_data: dataframe\n",
    "        index_data: dataframe\n",
    "\n",
    "    -------------------------\n",
    "    Returns: dataframe\n",
    "\n",
    "    '''\n",
    "    # merge dataframes\n",
    "    df = pd.merge(stock_data, index_data, how='inner',\n",
    "                  on='Date', suffixes=('', '_i'))\n",
    "    \n",
    "    df.columns = df.columns.str.lower()\n",
    "    df = df[['date','close', 'close_i']]\n",
    "\n",
    "    # shifting prices by one day ahead and merge\n",
    "    df = df.set_index('date')\n",
    "    shifted_next = df.shift(periods=-1)\n",
    "    df = pd.merge(df, shifted_next, on='date', suffixes=('', '_next')) #next day prices\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # shifting prices by one day back and merge\n",
    "    df = df.set_index('date')\n",
    "    shifted_prev = df.shift(periods=1)\n",
    "    df = pd.merge(df, shifted_prev, on='date', suffixes=('', '_prev')) #previous day prices\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # creating ratios\n",
    "    df['change'] = round(df['close'] / df['close_prev'] * 100 - 100, 4)\n",
    "    df['nextday'] = round(df['close_next'] / df['close'] * 100 - 100, 4)\n",
    "    df['change_i'] = round(df['close_i'] / df['close_i_prev'] * 100 - 100, 4)\n",
    "    df['nextday_i'] = round(df['close_i_next'] / df['close_i'] * 100 - 100, 4)\n",
    "\n",
    "    # adding trading holidays to the dataframe\n",
    "    dates = []\n",
    "    last_day = pd.to_datetime(stock_data.iloc[-1, 0], format='%Y-%m-%d')\n",
    "    for i in range(3650):\n",
    "        date = last_day - datetime.timedelta(days=i)\n",
    "        date = date.strftime('%Y-%m-%d')\n",
    "        dates.append(date)\n",
    "    date_df = pd.DataFrame(dates, columns=['date'])\n",
    "    df = pd.merge(date_df, df, on='date', how='left')\n",
    "\n",
    "    # fill in trading holidays with the following data (becaues dates are in reverse order, it is now ffill)\n",
    "    df = df.fillna(method='ffill')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(df):\n",
    "    df.loc[df['change'] > df['change_i'] + 0.5, 'label'] = 'good'\n",
    "\n",
    "    df.loc[df['change'] < df['change_i'] - 0.5, 'label'] = 'bad'\n",
    "\n",
    "    df.loc[df.label.isna(), 'label'] = 'neutral'\n",
    "    \n",
    "    df = df[['date', 'label']]\n",
    "    \n",
    "#     df.date = pd.to_datetime(df.date)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_label = label(price_ratios(tesla_stock, sp500))\n",
    "ford_label = label(price_ratios(ford_stock, sp500))\n",
    "ibm_label = label(price_ratios(ibm_stock, sp500))\n",
    "goldman_label = label(price_ratios(goldman_stock, sp500))\n",
    "boeing_label = label(price_ratios(boeing_stock, sp500))\n",
    "ge_label = label(price_ratios(ge_stock, sp500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good       1674\n",
       "bad        1342\n",
       "neutral    634 \n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_label.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Import headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "myclient = pymongo.MongoClient(\"mongodb://127.0.0.1:27017/\")\n",
    "news = myclient['news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_news = pd.DataFrame.from_records(news.tesla_news.find())\n",
    "ford_news = pd.DataFrame.from_records(news.ford_news.find())\n",
    "ibm_news = pd.DataFrame.from_records(news.ibm_news.find())\n",
    "goldman_news = pd.DataFrame.from_records(news.goldman_news.find())\n",
    "boeing_news = pd.DataFrame.from_records(news.boeing_news.find())\n",
    "ge_news = pd.DataFrame.from_records(news.ge_news.find())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Converting dates / restructuring dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_news(some_news):\n",
    "    some_news.date = pd.to_datetime(some_news.date).apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    some_news['text'] = some_news.headline +' '+ some_news.summary\n",
    "    some_news = some_news[['date', 'text', 'topic']]\n",
    "    return some_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_news = converting_news(tesla_news)\n",
    "ford_news = converting_news(ford_news)\n",
    "ibm_news = converting_news(ibm_news)\n",
    "goldman_news = converting_news(goldman_news)\n",
    "boeing_news = converting_news(boeing_news)\n",
    "ge_news = converting_news(ge_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Keeping just the relevant articles\n",
    "\n",
    "Relevant a headline or the summary, if it contains the keywords (basically the company name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant(text, keywords):\n",
    "    '''\n",
    "    Inputs:\n",
    "        text: string\n",
    "        keywords: list of string objects\n",
    "    Returns:\n",
    "        boolean\n",
    "    '''\n",
    "    for keyword in keywords:\n",
    "        if keyword in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def relevant_rows(df, keywords):\n",
    "    '''\n",
    "    Returns the rows of the dataframe, where the text is relevant\n",
    "    Input:\n",
    "        df: dataframe\n",
    "        keywords: list of string objects\n",
    "    Returns:\n",
    "        dataframe with the relevant rows\n",
    "    '''\n",
    "    df = df.loc[df.text.apply(lambda x: relevant(x, keywords))]\n",
    "    \n",
    "    print('Number of rows: ',len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  933\n"
     ]
    }
   ],
   "source": [
    "tesla_news = relevant_rows(tesla_news, ['Tesla'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  1447\n"
     ]
    }
   ],
   "source": [
    "ford_news = relevant_rows(ford_news, ['Ford'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  509\n"
     ]
    }
   ],
   "source": [
    "ibm_news = relevant_rows(ibm_news, ['IBM', 'International Business Machines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  1667\n"
     ]
    }
   ],
   "source": [
    "goldman_news = relevant_rows(goldman_news, ['Goldman'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  1629\n"
     ]
    }
   ],
   "source": [
    "boeing_news = relevant_rows(boeing_news, ['Boeing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  1085\n"
     ]
    }
   ],
   "source": [
    "ge_news = relevant_rows(ge_news, ['GE', 'General Electric'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Stemming/tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'stopwords' and 'negativewords' were originally based on the stopwords of nltk library. For this sentiment\n",
    "analysis I reviewed and modified the content of stopwords (removed keywords, added some not predicting words).\n",
    "Words that change completely the meaning of the following words (I call them like 'negative words') will be replaced simply with 'not'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any',\n",
    "                'are', 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'between', 'both', 'but', 'by',\n",
    "                'can', 'd', 'did', 'do', 'does', 'doing', 'during', 'each', 'few', 'for', 'from', 'further',\n",
    "                'had', 'has', 'have', 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his',\n",
    "                'how', 'i', 'if', 'in', 'into', 'is', 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "                'me', 'might', 'more', 'most', 'my', 'myself', 'neeed', 'now', 'o', 'of', 'off', 'on', 'once',\n",
    "                'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'u', 't',\n",
    "                'same', 'she', \"she's\", 'should', \"should've\", 'so', 'some', 'such', 'than', 'that', \"that'll\",\n",
    "                'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'k',\n",
    "                'those', 'through', 'to', 'too', 'until', 've', 'very', 'was', 'we', 'were', 'what', 'when',\n",
    "                'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'would', 'could', 'y',\n",
    "                'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves',\n",
    "                'mr', 'mrs', 'ms', 'nan', 'inc', 'co', 'com', 'wsj', 'monday', 'tuesday', 'wednesday', 'thursday',\n",
    "                'friday', 'saturday', 'sunday', 'either', 'shall', 'must', 'with', 'without', 'may']\n",
    "\n",
    "# my_negativewords = [\"aren't\", \"couldn't\", \"didn't\", \"doesn't\", \"don't\",\n",
    "#                     \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\",\n",
    "#                     'neither', 'nor', \"mustn't\", \"needn't\", 'no', \"shan't\",\n",
    "#                     \"shouldn't\", \"wasn't\", \"weren't\", \"won't\", \"wouldn't\"]\n",
    "\n",
    "\n",
    "my_negativewords = ['aren', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'mightn', 'no',\n",
    "                    'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn', 'neither', 'nor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def my_tokenizer(text):\n",
    "    # just keep the words (remove characters)\n",
    "    token_list = re.findall(r'([a-zA-Z0-9-]+)', text)\n",
    "\n",
    "    # lowercase\n",
    "    token_list = [t.lower() for t in token_list]\n",
    "\n",
    "    # remove stopwords\n",
    "    token_list = [word for word in token_list if word not in my_stopwords]\n",
    "\n",
    "    # replace negative words to 'not'\n",
    "    for i, word in enumerate(token_list):\n",
    "        if word in my_negativewords:\n",
    "            token_list[i] = 'not'\n",
    "    \n",
    "    # converting list into text\n",
    "    token_text = ' '.join(token_list)\n",
    "\n",
    "    return token_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_news['tokens'] = tesla_news.text.apply(my_tokenizer)\n",
    "ford_news['tokens'] = ford_news.text.apply(my_tokenizer)\n",
    "ibm_news['tokens'] = ibm_news.text.apply(my_tokenizer)\n",
    "goldman_news['tokens'] = goldman_news.text.apply(my_tokenizer)\n",
    "boeing_news['tokens'] = boeing_news.text.apply(my_tokenizer)\n",
    "ge_news['tokens'] = ge_news.text.apply(my_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Merging/concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla = pd.merge(tesla_news, tesla_label, how='left', on='date')\n",
    "ford = pd.merge(ford_news, ford_label, how='left', on='date')\n",
    "ibm = pd.merge(ibm_news, ibm_label, how='left', on='date')\n",
    "goldman = pd.merge(goldman_news, goldman_label, how='left', on='date')\n",
    "boeing = pd.merge(boeing_news, boeing_label, how='left', on='date')\n",
    "ge = pd.merge(ge_news, ge_label, how='left', on='date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([tesla, ford, ibm, goldman, boeing, ge])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Removing not relevant topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first I determine the relevant topics\n",
    "relevant_topics = data.topic.value_counts().index.to_list()[:34]\n",
    "for elem in ['PHOTOS', 'LETTERS', 'COMMENTARY', 'BOOKSHELF', 'RUMBLE SEAT']:\n",
    "    relevant_topics.remove(elem)\n",
    "\n",
    "def relevant_topic(topic):\n",
    "    if topic in relevant_topics:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "data = data.loc[data.topic.apply(lambda x: relevant_topic(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6202, 5)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = 'index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>tokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6200</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>GE Gains; Bad Day for Alcoa Stocks closed higher Thursday as analyst notes fueled a rally in GE, BofA and across the financial sector, although a downgrade sent Alcoa lower.</td>\n",
       "      <td>nan</td>\n",
       "      <td>ge gains bad day alcoa stocks closed higher analyst notes fueled rally ge bofa across financial sector although downgrade sent alcoa lower</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6201</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>GE Realigns Appliances, Lighting Unit is realigning the industrial business formerly part of the division that makes appliances and light bulbs.</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>ge realigns appliances lighting unit realigning industrial business formerly part division makes appliances light bulbs</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  \\\n",
       "6200  2010-01-08   \n",
       "6201  2010-01-05   \n",
       "\n",
       "                                                                                                                                                                               text  \\\n",
       "6200  GE Gains; Bad Day for Alcoa Stocks closed higher Thursday as analyst notes fueled a rally in GE, BofA and across the financial sector, although a downgrade sent Alcoa lower.   \n",
       "6201  GE Realigns Appliances, Lighting Unit is realigning the industrial business formerly part of the division that makes appliances and light bulbs.                                \n",
       "\n",
       "         topic  \\\n",
       "6200  nan        \n",
       "6201  BUSINESS   \n",
       "\n",
       "                                                                                                                                          tokens  \\\n",
       "6200  ge gains bad day alcoa stocks closed higher analyst notes fueled rally ge bofa across financial sector although downgrade sent alcoa lower   \n",
       "6201  ge realigns appliances lighting unit realigning industrial business formerly part division makes appliances light bulbs                      \n",
       "\n",
       "        label  \n",
       "6200  good     \n",
       "6201  neutral  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test = train_test_split(data,\n",
    "                                         test_size=.20,\n",
    "                                         random_state=10,\n",
    "                                         stratify=data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Save into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv('train.csv')\n",
    "data_test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
